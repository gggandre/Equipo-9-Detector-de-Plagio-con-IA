This paper navigates recent advancements in artificial intelligence (AI) and its growing prominence in the media. A significant focus is placed on Eliezer Yudkowsky, a prominent figure in artificial intelligence alignment, aiming to bridge the gap between public perceptions and rationalist viewpoints on AI technology. The analysis centers on Yudkowsky's proposed course of action for artificial intelligence, as outlined in his unpublished paper, "AGI Ruin: A List of Lethalities." This exploration involves understanding the concept of intelligence itself and establishing a reasonable working definition. This definition is then applied to contemporary AI capabilities and developments to assess its applicability to these technologies. The paper argues that contemporary AI systems possess some degree of intelligence. However, it posits that both weak and strong AI systems, lacking human-defined goals, would not inherently pose existential threats to humanity. This challenges prevailing notions of artificial intelligence alignment and raises questions about the validity of Nick Bostrom's Orthogonality Thesis. Furthermore, the paper discusses the possibility of artificial life emerging through the assembly of modules emulating separate cognitive functions.