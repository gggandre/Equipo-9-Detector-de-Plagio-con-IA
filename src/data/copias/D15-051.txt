With the rapid development of artificial intelligence, there is an increasing number of industries relying on the accuracy and efficiency of deep learning algorithms. However, due to the inexplicability and black box effect of deep neural networks, we can only obtain results without knowing the applied reasoning behind them. Hence derives the skepticism and resistance of some sectors of deep learning-based technologies. In the context of emotion analysis used in businesses and public opinion monitoring, it is sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines. Mathematical-based explanation methods often generalize emotion analysis as a classification task. Nevertheless, emotion should be distinct from other task categories because the generation of emotion involves human-specific factors and logic. This paper proposes an emotion analysis explanation framework that emphasizes considering the cause and trigger of emotions as the explanation for the deep learning-based emotion analysis, comprising two main components: the extraction of the emotion cause and the visualization of emotion-triggering words.