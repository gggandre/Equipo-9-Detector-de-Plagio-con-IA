The swift progress in artificial intelligence (AI) has prompted numerous industries to rely on the precision and efficacy of deep learning algorithms. However, due to the inscrutability and opaque nature of deep neural networks, outcomes are obtained without a clear understanding of the underlying rationale. This lack of transparency has led to skepticism and resistance from some sectors regarding technologies based on deep learning. In domains such as emotion analysis utilized in business and public opinion monitoring, decision-makers sometimes struggle to trust outcomes without explanations from ostensibly emotionless machines. Although mathematical-based explanation methods often categorize emotion analysis as a classification task, it should be noted that emotion differs from other task categories due to the involvement of human-specific factors and logic in its generation. This paper suggests an emotion analysis explanation framework grounded in psychological theories, emphasizing the consideration of emotion cause and trigger as explanations for deep learning-based emotion analysis. The framework comprises two primary components: extracting the emotion cause and visualizing emotion-triggering words.