Facial Expression Recognition (FER) finds applications in various fields such as education, gaming, robotics, healthcare, among others. Techniques like an interactive robot with Artificial Intelligence can recognize human faces, detect the emotions of the person it interacts with, and use these emotions to choose appropriate responses. One application of facial emotion detection is playing music based on the user's mood, where the user's facial expression is analyzed to deduce their feelings. In this paper, we implement such a system using a Convolutional Neural Network (CNN)-based deep learning approach. Deep learning is more effective than traditional machine learning in analyzing unstructured data, movies, and other media forms. Our research involves creating a real-time system capable of recognizing human faces, assessing human emotions, and recommending music to users. We utilized the OAHEGA and FER-2013 datasets for experimentation, training two emotion recognition models using various combinations of these datasets. The proposed model achieves an accuracy of 73.02%, predicting six emotions: anger, fear, joy, neutral, sadness, and surprise. This system can be deployed in various scenarios where real-time facial recognition is crucial.