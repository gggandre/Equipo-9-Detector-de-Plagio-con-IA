The quest for biologically inspired cognitive architectures (BICA) has propelled significant advancements in artificial intelligence (AI) and artificial general intelligence (AGI). However, most existing BICA models overlook a crucial aspect of human intelligence: emotions and feelings. This research delves into the development and implementation of an emotion-integrated cognitive architecture that mimics human emotional processing within a computational framework. Our proposed architecture, Emotion-Integrated Cognitive Architecture (EICA), draws inspiration from recent findings in cognitive psychology, neurobiology, neuroscience, and affective computing. EICA aims to embed emotional processing at the core of the AI system, enabling robust, flexible, and adaptable AI agents capable of responding to complex and dynamic environments with human-like emotional intelligence. Leveraging advances in brain imaging and recording techniques, the EICA model derives insights from the neural basis of emotions in humans. The architecture incorporates emotion-generating, recognition, and regulation mechanisms, enabling AI agents to perceive, interpret, and respond to emotions in themselves and others. This research presents the concept of EICA, delineating its modular structure and interactions with other cognitive components. It also showcases case studies demonstrating EICA's successful integration into various AI applications, including virtual assistants and adaptive robotics. This research marks a significant stride towards realizing the BICA Challenge by advancing the computational emulation of human emotional intelligence. By integrating emotions and feelings into AI systems, we edge closer to unlocking the full potential of bidirectional understanding between artificial and biological intelligences.