With the accuracy and efficiency of deep learning algorithms, there is an increasing number of industries relying on the rapid development of artificial intelligence. But knowing the applied reasoning behind them, we can only obtain results without due to the inexplicability and black box effect of deep neural networks. That engenders scepticism and resistance from some quarters of deep learning-based technologies. Sometimes difficult for decision-makers to trust the outcome without explanation from the supposedly emotionless machines, it is in the context of emotion analysis used in business and public opinion monitoring. Explanation methods often generalise emotion analysis as a classification task, but emotion should be different from other task categories because the generation of emotion involves human-specific factors and logic. This paper proposes an emotion analysis explanation framework grounded in psychological theories focusing on the stimulus from classic emotion theories, and it includes two main components: the extraction of the emotion cause and the visualisation of emotion-triggering words.