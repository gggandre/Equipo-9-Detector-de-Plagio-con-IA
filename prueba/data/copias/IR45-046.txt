The burgeoning performance of large language models (LLMs) has spurred speculation regarding the advent of theory of mind (ToM) in artificial intelligence (AI). LLMs demonstrate proficiency in attributing beliefs, desires, intentions, and emotions, with anticipated improvements in accuracy. However, their inability to empathize prompts inquiry into their capacity to honor individual exceptions, particularly in assessments of character and behavior prediction. This article posits empathy as a pivotal method for recognizing individual exceptions, distinct from predictive accuracy, wherein LLMs excel. A collaborative approach between psychology and computer science is advocated to refine empathy computing research, ensuring effective and ethical AI-driven empathetic interactions.